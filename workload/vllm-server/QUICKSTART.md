# Quick Start Guide

## 1ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°

### Step 1: í™˜ê²½ í™•ì¸
```bash
cd /home/skt6g/AI-RAN/KubeSMO/workload/vllm-server
./test_setup.sh
```

### Step 2: ì²« ë²ˆì§¸ Pod ë°°í¬ (ì•„ì§ ì•ˆ í–ˆë‹¤ë©´)
```bash
helm install test-1 /home/skt6g/AI-RAN/KubeSMO/workload/vllm-server \
  --set nodeName=sys-221he-tnr \
  --set gpuResource=nvidia.com/mig-1g.12gb \
  --set-string secret.hfApiToken=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 \
  --set server.modelPath=/root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct \
  --set server.port=8001 \
  --set server.service.port=8001 \
  --set server.service.targetPort=8001
```

### Step 3: ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
```bash
./run_autoscale.sh
```

ë! ğŸ‰

---

## ìƒì„¸ ì„¤ëª…

### ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ (ì„ íƒì‚¬í•­)

ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ:

```bash
# ê¸°ë³¸ (localhost:8001)
./monitor_metrics.sh

# ë˜ëŠ” ì»¤ìŠ¤í…€ í˜¸ìŠ¤íŠ¸/í¬íŠ¸
./monitor_metrics.sh 0.0.0.0 8001
```

ì¶œë ¥ ì˜ˆì‹œ:
```
============================================================
vLLM Metrics - 2025-01-15 10:30:00
============================================================

ğŸ“Š Request Queue Metrics:
   Waiting:  2
   Running:  4
   Swapped:  0
   âš ï¸  WARNING: Queue building up!

ğŸ’¾ Cache Usage:
   GPU Cache: 75.5%
   CPU Cache: 12.3%
```

### ìˆ˜ë™ ì‹¤í–‰ (ë” ë§ì€ ì˜µì…˜)

```bash
python3 autoscale_benchmark.py \
  --model /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct \
  --host 0.0.0.0 \
  --base-port 8001 \
  --num-prompts 1000 \
  --random-input-len 512 \
  --random-output-len 256 \
  --request-rate 5 \
  --check-interval 5
```

### íŒŒë¼ë¯¸í„° ì¡°ì •

ë” ë¹ ë¥´ê²Œ ìŠ¤ì¼€ì¼ ì•„ì›ƒì‹œí‚¤ë ¤ë©´:

```bash
# ë†’ì€ request rate
--request-rate 10

# ë” ìì£¼ ì²´í¬
--check-interval 3

# ë” ë§ì€ í”„ë¡¬í”„íŠ¸
--num-prompts 2000
```

---

## ì‹¤í–‰ íë¦„

1. **ë²¤ì¹˜ë§ˆí¬ ì‹œì‘** â†’ ì²« ë²ˆì§¸ pod (port 8001)ë¡œ ìš”ì²­ ì „ì†¡
2. **ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§** â†’ 5ì´ˆë§ˆë‹¤ `/metrics` ì²´í¬
3. **ìŠ¤ì¼€ì¼ ì¡°ê±´ ê°ì§€** â†’ `num_requests_waiting >= 1` ì´ 2ë²ˆ ë°œìƒ
4. **ìë™ ë°°í¬** â†’ ë‘ ë²ˆì§¸ pod (port 8002) Helm ë°°í¬
5. **ê³„ì† ì‹¤í–‰** â†’ ë‚˜ë¨¸ì§€ ìš”ì²­ ì²˜ë¦¬
6. **ê²°ê³¼ ì¶œë ¥** â†’ í†µê³„ í‘œì‹œ

---

## ì˜ˆìƒ ì¶œë ¥

```
============================================================
vLLM Auto-Scaling Benchmark
============================================================
Model: /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct
Base Port: 8001
Number of Prompts: 1000
Request Rate: 5 req/s
============================================================

âœ“ First pod is ready
âœ“ Metrics endpoint is accessible

Starting auto-scaling benchmark...

[10:30:00] num_requests_waiting: 0.0
[10:30:05] num_requests_waiting: 1.0
  â†’ Threshold exceeded (1/2)
[10:30:10] num_requests_waiting: 2.0
  â†’ Threshold exceeded (2/2)
  âœ“ Scale condition met!

ğŸš€ SCALING OUT at request 250/1000

============================================================
Deploying new pod: test-2 on port 8002
============================================================

Waiting for server at 0.0.0.0:8002 to be ready...
âœ“ Server at 0.0.0.0:8002 is ready!

============================================================
Single Pod Benchmark Results
============================================================
Duration:             120.45s
Completed requests:   1000
Failed requests:      0
Request throughput:   8.30 req/s
Token throughput:     2123.45 tok/s
============================================================

ğŸ¯ Scaled out! Now running on 2 pods

============================================================
Benchmark Complete!
============================================================
```

---

## ë¬¸ì œ í•´ê²°

### Podê°€ Ready ì•ˆ ë¨
```bash
kubectl get pods
kubectl logs test-1-vllm-server-xxx
```

### ë©”íŠ¸ë¦­ì´ ì•ˆ ë‚˜ì˜´
```bash
curl http://0.0.0.0:8001/metrics
```

### Helm ë°°í¬ ì‹¤íŒ¨
```bash
helm list
helm uninstall test-2  # ì¬ì‹œë„
```

---

## ì •ë¦¬

ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ í›„:

```bash
# ëª¨ë“  ë¦´ë¦¬ìŠ¤ ì‚­ì œ
helm uninstall test-1
helm uninstall test-2  # ìˆë‹¤ë©´
```

---

ë” ìì„¸í•œ ë‚´ìš©ì€ `README_AUTOSCALE.md`ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
